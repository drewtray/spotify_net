{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update spotify net/assign tracks\n",
    "\n",
    "> Update spotify net by assigning tracks with above a playcount threshold to an existing public playlist and removing from net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelPrep:\n",
    "    S3_BUCKET = 'spotify-net'\n",
    "    SCALER_FILE = 'scaler'\n",
    "    SVD_FILE = 'svd'\n",
    "    SPOTIFY_TRACKS_FILE = 'newer_tracks.csv'\n",
    "    LASTFM_TRACKS_FILE = 'last_fm_recent_tracks.csv'\n",
    "    GENRES_SVD_FILE = 'genres_svd.csv'\n",
    "    KEY_LIST_FILE = 'key_list.csv'\n",
    "    TIMESIG_LIST_FILE = 'timeSig_list.csv'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.svd = None\n",
    "        self.prepped_frame = None\n",
    "        self.genre_series = None\n",
    "        self.key_series = None\n",
    "        self.time_signature_series = None\n",
    "        self.s3_resource = boto3.resource('s3')\n",
    "    \n",
    "    def load_scaler(self):\n",
    "        scaler = self.s3_resource.Object(self.S3_BUCKET, self.SCALER_FILE).get()\n",
    "        self.scaler = pickle.loads(scaler['Body'].read())\n",
    "\n",
    "    def load_svd(self):\n",
    "        svd = self.s3_resource.Object(self.S3_BUCKET, self.SVD_FILE).get()\n",
    "        self.svd = pickle.loads(svd['Body'].read())\n",
    "\n",
    "    def load_tracks_data(self):\n",
    "        spotify_tracks = pd.read_csv(f's3://{self.S3_BUCKET}/{self.SPOTIFY_TRACKS_FILE}', index_col=0)\n",
    "        lastFM_tracks = pd.read_csv(f's3://{self.S3_BUCKET}/{self.LASTFM_TRACKS_FILE}', index_col=0)\n",
    "        spotify_tracks[['name', 'artist']] = spotify_tracks[['name', 'artist']].applymap(str.upper)\n",
    "        lastFM_tracks[['name', 'artist']] = lastFM_tracks[['name', 'artist']].applymap(str.upper)\n",
    "        self.prepped_frame = pd.merge(spotify_tracks, lastFM_tracks, on=['name', 'artist'])\n",
    "        self.prepped_frame = self.prepped_frame.drop([\n",
    "            'playcount', \n",
    "            'added at', \n",
    "            'artist id',\n",
    "            'id',\n",
    "            'type',\n",
    "            'track_href',\n",
    "            'analysis_url',\n",
    "            'type',\n",
    "            'diff',\n",
    "            'uri'\n",
    "        ], axis=1)\n",
    "    \n",
    "    def load_genre_series(self):\n",
    "        genre_series = pd.read_csv(f's3://{self.S3_BUCKET}/{self.GENRES_SVD_FILE}', index_col=0, squeeze=True)\n",
    "        self.genre_series = genre_series\n",
    "\n",
    "    def load_key_series(self):\n",
    "        key_series = pd.read_csv(f's3://{self.S3_BUCKET}/{self.KEY_LIST_FILE}', index_col=0, squeeze=True)\n",
    "        self.key_series = key_series\n",
    "\n",
    "    def load_time_signature_series(self):\n",
    "        time_signature_series = pd.read_csv(f's3://{self.S3_BUCKET}/{self.TIMESIG_LIST_FILE}', index_col=0, squeeze=True)\n",
    "        self.time_signature_series = time_signature_series\n",
    "\n",
    "    # Load genre, key, and time signature data. How is this list of genres being generated?\n",
    "    # These don't need to be loaded from S3, but I'm doing it anyway because...?     \n",
    "    def load_s3(self):\n",
    "        self.load_scaler()\n",
    "        self.load_svd()\n",
    "        self.load_tracks_data()\n",
    "        self.load_genre_series()\n",
    "        self.load_key_series()\n",
    "        self.load_time_signature_series()\n",
    "    \n",
    "    # TODO: should prepped frame be an argument? Why not an instance variable?\n",
    "    def transform_features(self, constant):\n",
    "        # ok, so order I'm log transforming before I'm applying the standard scaler later on? What is the interaction between these two operations generally?\n",
    "        # also, review feature selection process as it relates to feature transformation, and traditional order here\n",
    "\n",
    "        # Log-transform 'speechiness', 'acousticness', 'instrumentalness'\n",
    "        self.prepped_frame[['speechiness', 'acousticness', 'instrumentalness']] += constant\n",
    "        self.prepped_frame[['speechiness', 'acousticness', 'instrumentalness']] = np.log(self.prepped_frame[['speechiness', 'acousticness', 'instrumentalness']])\n",
    "\n",
    "        # One-hot encode 'key' and 'time_signature'\n",
    "        self.prepped_frame = pd.get_dummies(self.prepped_frame , prefix=['key', 'time_signature'], columns=['key', 'time_signature'])\n",
    "\n",
    "        # apply standardScaler to 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms':\n",
    "        columns_to_scale = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "        self.prepped_frame[columns_to_scale] = self.scaler.transform(self.prepped_frame[columns_to_scale])\n",
    "    \n",
    "    def update_dataframe_with_prefix(self, current_dataframe, series, prefix):\n",
    "        current_columns = current_dataframe.loc[:, current_dataframe.columns.str.startswith(prefix)]\n",
    "        all_columns = pd.DataFrame(np.zeros((len(current_dataframe), len(series))) , columns=series.tolist())\n",
    "        all_columns.update(current_columns)\n",
    "        current_dataframe = current_dataframe.loc[:, ~current_dataframe.columns.str.startswith(prefix)]\n",
    "\n",
    "        return pd.concat([current_dataframe, all_columns], axis=1)\n",
    "\n",
    "    def prepare_final_frame(self):\n",
    "        # One-hot encode genres and reduce to top 60 components using SVD\n",
    "        current_genres = self.prepped_frame.loc[:, self.prepped_frame.columns.str.startswith('genre_')]\n",
    "        all_genres = pd.DataFrame(np.zeros((len(self.prepped_frame), len(self.genre_series))) , columns=self.genre_series.tolist())\n",
    "        all_genres = all_genres.add_prefix('genre_')\n",
    "        all_genres.update(current_genres)\n",
    "        all_genres.columns = all_genres.columns.str.replace('genre_', '')\n",
    "\n",
    "        # Reduce features to top 60 components\n",
    "        transformed_genres = pd.DataFrame(self.svd.transform(all_genres))\n",
    "        transformed_genres = transformed_genres.add_prefix('genre_')\n",
    "\n",
    "        self.prepped_frame = self.prepped_frame.loc[:, ~self.prepped_frame.columns.str.startswith('genre_')]\n",
    "        self.prepped_frame = pd.concat([self.prepped_frame, transformed_genres], axis=1)\n",
    "\n",
    "        # One-hot encode keys and time signatures\n",
    "        self.prepped_frame = self.update_dataframe_with_prefix(self.prepped_frame, self.key_series, 'key_')\n",
    "        self.prepped_frame = self.update_dataframe_with_prefix(self.prepped_frame, self.time_signature_series, 'time_signature_')\n",
    "\n",
    "    def save_prepared_frame(self):\n",
    "        self.prepped_frame.to_csv(f's3://{self.S3_BUCKET}/for_prediction.csv')\n",
    "        print(self.prepped_frame.shape)\n",
    "        print('Uploaded to S3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 90)\n",
      "Uploaded to S3\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if __name__ == '__main__':\n",
    "    frame = ModelPrep()\n",
    "    frame.load_s3()\n",
    "    frame.transform_features(0.0000001)\n",
    "    frame.prepare_final_frame()\n",
    "    frame.save_prepared_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
